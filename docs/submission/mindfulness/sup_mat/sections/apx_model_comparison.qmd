In this section, we elaborate on the statistical methodology utilized to assess the impact of contextual variables on State Self-Compassion (SSC). Our analysis specifically focuses on three key areas: differences across individuals, variations between days within the same individual, and fluctuations within a single day for each individual.

Prior to implementing the final Bayesian hierarchical models, we embarked on a rigorous model selection process. This process was essential for determining the most fitting structures for both random and fixed effects within our dataset. In the final models, we examined the SC and USC aspects of SSC as a function of nine predictors: negative affect, decentering, and context evaluation. Each of these predictors was uniquely centered to distinctly capture and differentiate the three dimensions of variance we were interested in -- namely, inter-individual differences, between-day variations within individuals, and within-day fluctuations for each individual. This nuanced approach allowed us to comprehensively understand and articulate the influences shaping SSC.

Our approach commenced by exploring the full fixed-effect structure and proceeded with a systematic comparison of models featuring varying degrees of random-effect complexity. Once we determined the optimal random-effect structure, we turned our attention to assessing models with different fixed-effects configurations. To facilitate this thorough model comparison, we used the Leave-One-Out (LOO) method, a robust Bayesian model selection technique implemented within Stan.

The optimal structure for our model—encompassing both random effects and fixed effects—was determined through a model comparison process. Prior to analysis, all numerical variables were standardized to enhance both comparability and interpretability. To determine the best model fit, we utilized the Leave-One-Out Cross-Validation (LOO) procedure. This technique evaluates out-of-sample prediction accuracy by sequentially excluding individual observations from the dataset and assessing the model’s performance on these excluded points. Models demonstrating lower LOO values were interpreted as having superior fit and enhanced predictive accuracy. In our modeling process, we integrated regularizing priors, which served to mitigate overfitting by applying constraints that direct the model towards more plausible outcomes. Additionally, we employed partial pooling to boost the accuracy of estimations across various groups. We fitted the models using the cmdstan interface and with the brms package, which leverages the computational power of Stan for Bayesian inference.

#### Model Comparison for SC

##### Random-Effects

```{r}
#| echo: false
# Random-Effects Table Data
random_effects_data <- data.frame(
  Model = c("Model 1: Basic Model", 
            "Model 2: Add Random Effect for user_id", 
            "Model 3: Add Random Effects for user_id and user_id:day", 
            "Model 4: Add Random Slopes for na_moment, na_day on user_id", 
            "Model 5: Add Random Slopes for na_moment, na_day, dec_moment, dec_day on user_id", 
            "Model 6: Complex Random Effects Structure"),
  elpd_diff = c(0.00, -0.65, -55.87, -277.64, -789.64, -3072.14),
  se_diff = c(0.00, 1.47, 14.09, 30.44, 48.57, 80.86),
  elpd_loo = c(-4819.22, -4819.87, -4875.09, -5096.86, -5608.86, -7891.36),
  se_elpd_loo = c(82.58, 82.64, 81.77, 79.42, 72.49, 56.66),
  p_loo = c(1730.98, 1722.29, 1650.03, 1482.20, 196.06, 12.09),
  se_p_loo = c(19.54, 19.54, 19.08, 17.14, 3.23, 0.25),
  looic = c(9638.43, 9639.73, 9750.18, 10193.72, 11217.72, 15782.72),
  se_looic = c(165.15, 165.28, 163.54, 158.84, 144.973, 113.32)
)

# Print the table using kable and kableExtra
kable(random_effects_data, "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 7) %>%
  column_spec(1, width = "3cm") %>%
  column_spec(2, width = "1.1cm") %>%
  column_spec(3, width = "1.1cm") %>%
  column_spec(4, width = "1.6cm") %>%
  column_spec(5, width = "1.6cm") %>%
  column_spec(6, width = "1.1cm") %>%
  column_spec(7, width = "1.1cm") %>%
  column_spec(8, width = "1.1cm") %>%
  column_spec(9, width = "1.1cm")
```

The model comparison, utilizing the LOO method, clearly suggests that there is no valid justification for employing a random-effect structure more complex than participant-level clustering. In other words, the simpler approach of clustering at the participant level provides an adequate representation for our data, as evidenced by the minimal improvements gained from more intricate random-effect structures.

##### Fixed-Effects


```{r}
#| echo: false
# Second Random-Effects Table Data
second_random_effects_data <- data.frame(
  Model = c("Model 1: Full Fixed Effects", 
            "Model 2: With na and dec", 
            "Model 3: With na and con", 
            "Model 4: With dec and con", 
            "Model 5: Only na", 
            "Model 6: Only dec", "Model 7: Only con"),
  elpd_diff = c(0.00, -24.71, -221.87, -250.38, -309.08, -483.33, -845.25),
  se_diff = c(0.00, 8.09, 23.34, 25.10, 28.15, 34.13, 47.41),
  elpd_loo = c(-5608.30, -5633.01, -5830.17, -5858.68, -5917.38, -6091.63, -6453.55),
  se_elpd_loo = c(72.50, 72.60, 73.91, 74.20, 72.58, 72.61, 77.22),
  p_loo = c(195.10, 192.53, 196.57, 195.13, 193.20, 189.76, 197.08),
  se_p_loo = c(3.20, 3.15, 3.20, 3.19, 3.17, 3.08, 3.06),
  looic = c(11216.60, 11266.02, 11660.33, 11717.36, 11834.75, 12183.26, 12907.10),
  se_looic = c(144.99, 145.21, 147.81, 148.39, 145.16, 145.22, 154.43)
)

# Print the table using kable and kableExtra
kable(second_random_effects_data, "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 7) %>%
  column_spec(1, width = "3cm") %>%
  column_spec(2, width = "1.1cm") %>%
  column_spec(3, width = "1.1cm") %>%
  column_spec(4, width = "1.6cm") %>%
  column_spec(5, width = "1.6cm") %>%
  column_spec(6, width = "1.1cm") %>%
  column_spec(7, width = "1.1cm") %>%
  column_spec(8, width = "1.1cm") %>%
  column_spec(9, width = "1.1cm")
```

Based on the model comparison using the LOO method, the best-fitting model is "Model 1: Full Fixed Effects." It exhibits the highest estimated log pointwise predictive density (elpd_loo) and the lowest Leave-One-Out Information Criterion (looic), suggesting superior predictive performance compared to the other models.


#### Model Comparison for USC

In parallel with our analysis of the SC component, we conducted a comprehensive model comparison for the USC component. This comparison aimed to identify the most appropriate random-effect and fixed-effect structures for our dataset, similar to the approach taken for the SC component.

##### Random-Effects

```{r}
#| echo: false
# Third Random-Effects Table Data
third_random_effects_data <- data.frame(
  Model = c("Model 1: Basic Model", "Model 2: Add Random Effect for user_id", 
            "Model 3: Add Random Effects for user_id and user_id:day", 
            "Model 4: Add Random Slopes for na_moment, na_day on user_id", 
            "Model 5: Add Random Slopes for na_moment, na_day, dec_moment, dec_day on user_id", 
            "Model 6: Complex Random Effects Structure"),
  elpd_diff = c(0.00, -1.62, -100.70, -244.97, -909.65, -2907.03),
  se_diff = c(0.00, 1.62, 19.06, 29.47, 48.75, 79.75),
  elpd_loo = c(-4092.92, -4094.54, -4193.62, -4337.88, -5002.57, -6999.95),
  se_elpd_loo = c(79.00, 79.05, 77.89, 76.22, 70.57, 61.17),
  p_loo = c(1811.52, 1864.36, 1649.19, 1554.81, 186.52, 12.20),
  se_p_loo = c(21.20, 21.52, 19.39, 18.70, 3.03, 0.26),
  looic = c(8185.83, 8189.08, 8387.24, 8675.76, 10005.13, 13999.89),
  se_looic = c(158.00, 158.11, 155.78, 152.45, 141.15, 122.34)
)

# Print the table using kable and kableExtra
kable(third_random_effects_data, "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 7) %>%
  column_spec(1, width = "3cm") %>%
  column_spec(2, width = "1.1cm") %>%
  column_spec(3, width = "1.1cm") %>%
  column_spec(4, width = "1.6cm") %>%
  column_spec(5, width = "1.6cm") %>%
  column_spec(6, width = "1.1cm") %>%
  column_spec(7, width = "1.1cm") %>%
  column_spec(8, width = "1.1cm") %>%
  column_spec(9, width = "1.1cm")
```

Our evaluation of random-effect structures using the LOO method yielded results consistent with those observed for the SC component. The model comparison for USC indicates that there is no compelling justification for employing a random-effect structure more complex than clustering at the participant level. This echoes the findings from the SC component analysis, where participant-level clustering proved sufficient to adequately represent our data. In both cases, more intricate random-effect structures did not significantly improve model performance.

##### Fixed-Effects

```{r}
#| echo: false
# Third Random-Effects Table Data
third_random_effects_data <- data.frame(
  Model = c("Model 1: Basic Model", "Model 2: Add Random Effect for user_id", 
            "Model 3: Add Random Effects for user_id and user_id:day", 
            "Model 4: Add Random Slopes for na_moment, na_day on user_id", 
            "Model 5: Add Random Slopes for na_moment, na_day, dec_moment, dec_day on user_id", 
            "Model 6: Complex Random Effects Structure"),
  elpd_diff = c(0.00, -1.62, -100.70, -244.97, -909.65, -2907.03),
  se_diff = c(0.00, 1.62, 19.06, 29.47, 48.75, 79.75),
  elpd_loo = c(-4092.92, -4094.54, -4193.62, -4337.88, -5002.57, -6999.95),
  se_elpd_loo = c(79.00, 79.05, 77.89, 76.22, 70.57, 61.17),
  p_loo = c(1811.52, 1864.36, 1649.19, 1554.81, 186.52, 12.20),
  se_p_loo = c(21.20, 21.52, 19.39, 18.70, 3.03, 0.26),
  looic = c(8185.83, 8189.08, 8387.24, 8675.76, 10005.13, 13999.89),
  se_looic = c(158.00, 158.11, 155.78, 152.45, 141.15, 122.34)
)

# Print the table using kable and kableExtra
kable(third_random_effects_data, "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(latex_options = c("repeat_header"), font_size = 7) %>%
  column_spec(1, width = "3cm") %>%
  column_spec(2, width = "1.1cm") %>%
  column_spec(3, width = "1.1cm") %>%
  column_spec(4, width = "1.6cm") %>%
  column_spec(5, width = "1.6cm") %>%
  column_spec(6, width = "1.1cm") %>%
  column_spec(7, width = "1.1cm") %>%
  column_spec(8, width = "1.1cm") %>%
  column_spec(9, width = "1.1cm")
```

When considering fixed-effect structures for the USC component, our analysis identified 'Model 1: Full Fixed Effects' as the best-fitting model. This model exhibited the highest estimated log pointwise predictive density (elpd_loo) and the lowest Leave-One-Out Information Criterion (looic) among the options. These results closely mirror the findings from the SC component analysis, where 'Model 1: Full Fixed Effects' also emerged as the preferred model.

#### Summary

The congruence in results between the SC and USC components underscores the consistency and reliability of our modeling approach. It reinforces the notion that simpler model structures, both in terms of random effects and fixed effects, effectively capture the essential characteristics of our data. Therefore, for both SC and USC, we have selected 'Model 1: Full Fixed Effects' as the optimal model, demonstrating superior predictive performance compared to more complex alternatives.


#### Final Model

The final model for predicting the negative component of State Self-Compassion is as follows:

$$
\begin{aligned}
usc &\sim \text{Student-t}(\mu, \sigma, \nu) \\
\mu &= \beta_{0} + \beta_{\text{dec\_moment}} \times \text{dec\_moment} + \beta_{\text{dec\_day}} \times \text{dec\_day} + \beta_{\text{dec\_person}} \times \text{dec\_person} + \\
&\quad \beta_{\text{na\_moment}} \times \text{na\_moment} + \beta_{\text{na\_day}} \times \text{na\_day} + \beta_{\text{na\_person}} \times \text{na\_person} + \\
&\quad \beta_{\text{context\_moment}} \times \text{context\_moment} + \beta_{\text{context\_day}} \times \text{context\_day} + \\
&\beta_{\text{context\_person}} \times \text{context\_person} + \\
&\quad b_{\text{user\_id}}[j] + b_{\text{bysubj\_day}}[k] \\
b_{\text{user\_id}}[j] &\sim \mathcal{N}(0, \Sigma_{\text{user\_id}}) \\
b_{\text{bysubj\_day}}[k] &\sim \mathcal{N}(0, \sigma^2_{\text{bysubj\_day}}) \\
\beta &\sim \text{priors1} \\
\sigma &\sim \text{Half-Cauchy}(0, \text{scale}) \\
\nu &\sim \text{Exponential}(\text{rate}) \\
\\
\text{Where:} & \\
\Sigma_{\text{user\_id}} &= \text{Full covariance matrix for random effects within user\_id} \\
\sigma^2_{\text{bysubj\_day}} &= \text{Var}(b_{\text{bysubj\_day}}[k])
\end{aligned}
$$

The model was estimated using a Student's t-distribution with identity links for the mean (mu), scale (sigma), and degrees of freedom (nu). The analysis was based on 6741 observations, with the posterior distribution derived from 2000 post-warmup draws across two chains.

#### Group-Level Effects

- **By-Subject-Day Variability**: The standard deviation of the random intercepts for different days (`bysubj_day`) was estimated to be 0.02, suggesting minimal variability in the negative component of State Self-Compassion across days within subjects.
- **By-User Variability**: The model revealed substantial between-person variability in the intercept (0.50), indicating differences in baseline levels of the negative component of State Self-Compassion among participants. The variability in the within-person components of negative affect (`na_moment`: 0.06, `na_day`: 0.15), context (`context_moment`: 0.02, `context_day`: 0.09), and decentering (`dec_moment`: 0.08, `dec_day`: 0.14) suggests individual differences in how these factors relate to self-compassion on a moment-to-moment and day-to-day basis.

#### Population-Level Effects

- **Decentering**: Momentary ($\beta$ = -0.12), daily ($\beta$ = -0.18), and person-level ($\beta$ = -0.37) decentering showed negative associations with the negative component of State Self-Compassion, indicating that higher levels of decentering are associated with lower levels of self-criticism or negative self-judgment.
- **Negative Affect**: Momentary ($\beta$ = 0.13) and day-level ($\beta$ = 0.17) negative affect were positively associated with the negative component, while person-level negative affect ($\beta$ = 0.34) showed a stronger positive relationship. This suggests that both transient and enduring negative emotions contribute to increased self-criticism.
- **Context Valence**: Momentary context valence showed a weak negative association ($\beta$ = -0.02), while daily ($\beta$ = 0.01) and person-level context valence ($\beta$ = 0.04) had minimal or slightly positive associations, indicating that the immediate context's perceived negativity might slightly increase self-critical thoughts.

#### Family Specific Parameters

- The estimated scale parameter ($\sigma$ = 0.35) and degrees of freedom ($\nu$ = 4.20) of the Student's t-distribution reflect the variability and the heaviness of the tails in the model residuals, respectively.

#### Model Diagnostics

The model diagnostics indicate satisfactory convergence with Rhat values close to 1 for all parameters. The Bulk_ESS and Tail_ESS values suggest adequate effective sample sizes for reliable estimation and inference.
